<ol>
<li>Null-text inversion for editing real images using guided diffusion models (CVPR 2023)
<li>Plug-and-play diffusion features for text-driven image-to-image translation (CVPR 2023)
<li>Scaling In-The-Wild Training for Diffusion-Based Illumination Harmonization and Editing by Imposing Consistent Light Transport (ICLR 2025)
<li>EditGAN: High-Precision Semantic Image Editing (NeurIPS 2021)
<li>Maskgan: Towards diverse and interactive facial image manipulation (CVPR 2020)
<li>SemanticStyleGAN: Learning Compositional Generative Priors for Controllable Image Synthesis and Editing (CVPR 2022)
<li>Imagic: Text-Based Real Image Editing with Diffusion Models (CVPR 2023)
<li>MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing (ICCV 2023)
<li>Dragdiffusion: Harnessing diffusion models for interactive point-based image editing (CVPR 2024)
<li>Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation (CVPR 2024)
<li>StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing (arxiv 2023)
<li>Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models (arxiv 2023)
<li>LIGHTNING-FAST IMAGE INVERSION AND EDITING FOR TEXT-TO-IMAGE DIFFUSION MODELS (ICLR 2025)
<li>Effective real image editing with accelerated iterative diffusion inversion
<li>ReNoise: Real Image Inversion Through Iterative Noising
</ol>
