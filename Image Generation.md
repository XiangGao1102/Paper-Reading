<ol>
<li>Nichol A Q, Dhariwal P, Ramesh A, et al. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models[C]//Proceedings of the International Conference on Machine Learning. PMLR, 2022: 16784-16804.
<li>Saharia C, Chan W, Saxena S, et al. Photorealistic text-to-image diffusion models with deep language understanding[C]//Proceedings of the International Conference on Neural Information Processing Systems. 2022: 36479-36494.
<li>Ramesh A, Dhariwal P, Nichol A, et al. Hierarchical Text-Conditional Image Generation with CLIP Latents[J]. arXiv preprint arXiv:2204.06125, 2022.
<li>Geng D, Park I, Owens A. Visual anagrams: Generating multi-view optical illusions with diffusion models[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2024: 24154-24163.</li>
<li>Wang X, Darrell T, Rambhatla S S, et al. Instancediffusion: Instance-level control for image generation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 6232-6242.
<li>Avrahami O, Hayes T, Gafni O, et al. Spatext: Spatio-textual representation for controllable image generation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 18370-18380.
<li>Li Y, Liu H, Wu Q, et al. Gligen: Open-set grounded text-to-image generation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 22511-22521.
<li>Xie J, Li Y, Huang Y, et al. Boxdiff: Text-to-image synthesis with training-free box-constrained diffusion[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 7452-7461.
</ol>

